{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f73d72-c71d-43a8-9f79-77b1b0e28fc0",
   "metadata": {},
   "source": [
    "## 🛜 필수 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8498d408-5079-43c0-a64c-ae0c6f3f178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e1d3724-4f20-4921-a27f-3811bfba42c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- YTN 메인 메뉴 HTML 스니펫 (제공해주신 내용) ---\n",
    "# 이 HTML을 파싱하여 카테고리 맵을 생성합니다.\n",
    "ytn_menu_html_snippet = \"\"\"\n",
    "                <ul class=\"menu\">\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainpolitics menu_election2025\">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/issue/election2025\">대선2025</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainpolitics \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0101\">정치</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_maineconomy \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0102\">경제</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainsociety \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn\n",
    "                        .co.kr/news/list.php?mcd=0103\">사회</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainnationwide \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0115\">전국</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainglobal \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0104\">국제</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainscience \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0105\">과학</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainculture \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0106\">문화</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainsports \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0107\">스포츠</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainphoto \">\n",
    "\t\t\t\t\t\t<a href=\"https://star.ytn.co.kr\">연예</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_maingame \">\n",
    "\t\t\t\t\t\t<!--<a href=\"https://game.ytn.co.kr/news/list.php?mcd=0135\">게임</a>-->\n",
    "\t\t\t\t\t\t<a href=\"https://game.ytn.co.kr\">게임</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainweather \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/weather/list_weather.php\">날씨</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainissue \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/main_issue.html\">이슈</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainyp \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/main_yp.html\">시리즈</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainreplay \"><a href=\"https://www.ytn.co.kr/replay/main.html\">TV프로그램</a></li>\n",
    "\t\t\t\t</ul>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dc7b105-506a-4f51-af90-568c7eb65877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 메뉴 HTML 파싱 및 카테고리 맵 생성 ---\n",
    "ytn_menu_soup = BeautifulSoup(ytn_menu_html_snippet, 'html.parser')\n",
    "ytn_category_map = {} # 카테고리 맵 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16948c74-8d77-4a4a-88fd-060154616d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 생성된 YTN 카테고리 맵 ---\n",
      "{'0101': '정치', '0102': '경제', '0103': '사회', '0115': '전국', '0104': '국제', '0105': '과학', '0106': '문화', '0107': '스포츠'}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 메뉴 HTML에서 a 태그들을 찾습니다.\n",
    "menu_links = ytn_menu_soup.select('ul.menu a')\n",
    "\n",
    "for link in menu_links:\n",
    "    href = link.get('href')\n",
    "    text = link.get_text(strip=True)\n",
    "    if href and text:\n",
    "        parsed_url = urlparse(href)\n",
    "        # URL 경로가 '/news/list.php'이고 쿼리 스트링에 'mcd' 파라미터가 있는 경우\n",
    "        if parsed_url.path == '/news/list.php' and parsed_url.query:\n",
    "            query_params = parse_qs(parsed_url.query)\n",
    "            if 'mcd' in query_params and query_params['mcd'][0]:\n",
    "                mcd_code = query_params['mcd'][0]\n",
    "                ytn_category_map[mcd_code] = text # mcd 코드를 키로, 카테고리 이름을 값으로 저장\n",
    "                # print(f\"맵핑 추가: {mcd_code} -> {text}\") # 디버깅용 출력\n",
    "\n",
    "# 생성된 카테고리 맵 확인 (선택 사항)\n",
    "print(\"--- 생성된 YTN 카테고리 맵 ---\")\n",
    "print(ytn_category_map)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e91404df-8782-44ae-8efd-cb83aab8bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ytn_category_from_url(url, category_map):\n",
    "    \"\"\"\n",
    "    YTN 기사 URL 경로를 분석하여 카테고리 코드를 추출하고 맵핑된 카테고리 이름을 반환합니다.\n",
    "    생성된 category_map을 사용합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed_url = urlparse(url)\n",
    "        path = parsed_url.path # 예: '/_ln/0103_202505111017133914'\n",
    "        path_segments = path.split('/')\n",
    "        \n",
    "        if '_ln' in path_segments:\n",
    "            ln_index = path_segments.index('_ln')\n",
    "            if ln_index + 1 < len(path_segments):\n",
    "                # 예: '0103_202505111017133914'\n",
    "                code_segment = path_segments[ln_index + 1]\n",
    "                # 코드 세그먼트에서 첫 번째 '_' 이전 부분이 카테고리 코드입니다.\n",
    "                code = code_segment.split('_')[0] if '_' in code_segment else code_segment\n",
    "\n",
    "                # 생성된 category_map에서 코드를 찾아 카테고리 이름 반환\n",
    "                return category_map.get(code, f\"알 수 없는 카테고리 코드: {code}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"URL [{url}] 카테고리 분석 중 오류 발생: {e}\")\n",
    "\n",
    "    # 일치하는 패턴을 찾지 못하거나 오류 발생 시\n",
    "    return \"카테고리 분류 실패 (URL 패턴 불일치)\"\n",
    "\n",
    "def get_ytn_article_data(url, headers, category_map):\n",
    "    \"\"\"\n",
    "    단일 YTN 기사 URL에서 제목, 본문, 카테고리를 추출하는 함수\n",
    "    생성된 category_map을 인자로 받습니다.\n",
    "    \"\"\"\n",
    "    news_title = \"제목 추출 실패\"\n",
    "    news_body = \"본문 추출 실패\"\n",
    "    news_category = \"카테고리 추출 실패\" # 초기 카테고리 상태\n",
    "\n",
    "    print(f\"Processing URL: {url}\")\n",
    "\n",
    "    try:\n",
    "        # 1. 웹페이지 HTML 가져오기\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        html_content = response.text\n",
    "\n",
    "        # --- 디버깅: 가져온 HTML을 파일로 저장 ---\n",
    "        file_name_safe = re.sub(r'[^\\w.-]', '_', urlparse(url).path.strip('/')).strip('_')\n",
    "        if not file_name_safe: file_name_safe = urlparse(url).hostname or 'debug'\n",
    "        debug_file_path = f\"debug_ytn_html_{file_name_safe}.html\"\n",
    "        try:\n",
    "            with open(debug_file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(html_content)\n",
    "            print(f\"디버깅: 가져온 HTML 내용을 '{debug_file_path}' 파일로 저장했습니다.\")\n",
    "        except Exception as file_error:\n",
    "            print(f\"디버깅: HTML 파일 저장 중 오류 발생: {file_error}\")\n",
    "        # --- 디버깅 끝 ---\n",
    "\n",
    "        # 2. BeautifulSoup으로 파싱\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # --- 뉴스 제목 추출 (제공해주신 YTN 구조 반영) ---\n",
    "        # h2 태그에 class 'news_title'를 찾고, 그 안의 span 텍스트를 가져옵니다.\n",
    "        title_element_h2 = soup.find('h2', class_='news_title')\n",
    "\n",
    "        if title_element_h2:\n",
    "            title_element_span = title_element_h2.find('span')\n",
    "            if title_element_span:\n",
    "                news_title = title_element_span.get_text(strip=True)\n",
    "                print(f\"URL {url}: 제목 요소 (h2.news_title > span) 추출 성공.\")\n",
    "            else:\n",
    "                 news_title = title_element_h2.get_text(strip=True) if title_element_h2.get_text(strip=True) else news_title\n",
    "                 print(f\"URL {url}: <h2 class='news_title'> 태그를 찾았으나 <span>이 없어 <h2> 텍스트 추출 시도.\")\n",
    "        else:\n",
    "            print(f\"URL {url}: 제목 요소를 찾지 못했습니다. (예상 선택자: h2.news_title)\")\n",
    "\n",
    "\n",
    "        # --- 뉴스 본문 추출 (제공해주신 div#CmAdContent.paragraph 구조 반영) ---\n",
    "        # 본문 전체를 감싸는 div 요소를 찾습니다. id가 'CmAdContent'이고 class가 'paragraph'입니다.\n",
    "        body_container = soup.find('div', id='CmAdContent', class_='paragraph')\n",
    "        \n",
    "        news_body = \"본문 추출 실패\"\n",
    "\n",
    "        if body_container:\n",
    "            # 불필요한 요소 (예: iframe 광고, 이미지 등) 제거\n",
    "            for unnecessary_tag in body_container.find_all(['iframe', 'figure']):\n",
    "                unnecessary_tag.extract()\n",
    "\n",
    "            news_body_raw = body_container.get_text(separator='\\n', strip=True)\n",
    "\n",
    "            # 불필요한 내용 제거 및 정리 (YTN 기사 하단부 패턴 제거)\n",
    "            cleaned_body = news_body_raw\n",
    "            cleaned_body = re.sub(r'YTN\\s*[^(\\n)]+\\s*\\([^@]+\\@[^)]+\\)\\s*\\n*', '', cleaned_body, flags=re.MULTILINE)\n",
    "            cleaned_body = re.sub(r'※\\s*.*?\\[메일\\].*?\\n*', '', cleaned_body, flags=re.DOTALL)\n",
    "            cleaned_body = re.sub(r'\\[저작권자\\(c\\).+?\\]\\n*', '', cleaned_body)\n",
    "\n",
    "            news_body = re.sub(r'\\n\\s*\\n', '\\n\\n', cleaned_body).strip()\n",
    "\n",
    "            if news_body:\n",
    "                print(f\"URL {url}: 본문 요소 (div#CmAdContent.paragraph) 추출 성공.\")\n",
    "            else:\n",
    "                print(f\"URL {url}: 본문 컨테이너는 찾았으나, 유효한 텍스트 내용이 없습니다 (정리 후 빈 내용).\")\n",
    "                news_body = \"본문 내용 없음\"\n",
    "\n",
    "        else:\n",
    "            print(f\"URL {url}: 본문 전체 컨테이너 요소를 찾지 못했습니다. (예상 선택자: div#CmAdContent.paragraph)\")\n",
    "\n",
    "        # --- 뉴스 카테고리 추출 (URL 경로 분석 - 생성된 맵 사용) ---\n",
    "        # 생성된 ytn_category_map을 classify_ytn_category_from_url 함수에 전달\n",
    "        news_category = classify_ytn_category_from_url(url, category_map)\n",
    "        if news_category == \"카테고리 분류 실패 (URL 패턴 불일치)\" or news_category.startswith(\"알 수 없는 카테고리 코드\"):\n",
    "             print(f\"URL {url}: URL 구조 분석으로 카테고리 추출/분류 실패: {news_category}\")\n",
    "        else:\n",
    "             print(f\"URL {url}: URL 구조 분석으로 카테고리 '{news_category}' 추출 성공.\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"URL {url}: 웹페이지를 가져오는 중 오류 발생: {e}\")\n",
    "        # 요청 실패 시 제목, 본문, 카테고리는 초기 실패 값 유지\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"URL {url}: 데이터 처리 중 예외 발생: {e}\")\n",
    "        # 데이터 처리 중 오류 발생 시 해당 값들은 초기 실패 값 유지\n",
    "        if news_category == \"카테고리 추출 실패\": # 오류 발생했더라도 카테고리라도 추출 시도\n",
    "             news_category = classify_ytn_category_from_url(url, category_map) # 맵을 전달\n",
    "\n",
    "    # 최종 추출 결과 반환\n",
    "    return {\n",
    "        'URL': url,\n",
    "        '제목': news_title,\n",
    "        '본문': news_body,\n",
    "        '카테고리': news_category\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd7dd282-30f3-4d44-9f29-cb02a5266063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 크롤링할 YTN 뉴스 기사 URL 목록을 작성해주세요. ---\n",
    "news_urls_to_crawl = [\n",
    "    'https://www.ytn.co.kr/_ln/0102_202505111058245968'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6419b43-6150-47c2-94b8-1161c3525827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-Agent 설정\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4910f8ab-dc6f-43c2-a171-cb3fdae886ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL: https://www.ytn.co.kr/_ln/0102_202505111058245968\n",
      "디버깅: 가져온 HTML 내용을 'debug_ytn_html_ln_0102_202505111058245968.html' 파일로 저장했습니다.\n",
      "URL https://www.ytn.co.kr/_ln/0102_202505111058245968: 제목 요소 (h2.news_title > span) 추출 성공.\n",
      "URL https://www.ytn.co.kr/_ln/0102_202505111058245968: 본문 요소 (div#CmAdContent.paragraph) 추출 성공.\n",
      "URL https://www.ytn.co.kr/_ln/0102_202505111058245968: URL 구조 분석으로 카테고리 '경제' 추출 성공.\n",
      "------------------------------\n",
      "\n",
      "모든 URL 처리 완료.\n"
     ]
    }
   ],
   "source": [
    "# 추출된 데이터를 저장할 리스트\n",
    "extracted_data_list = []\n",
    "\n",
    "# 각 URL에 대해 크롤링 및 데이터 추출 반복\n",
    "for url in news_urls_to_crawl:\n",
    "    # 카테고리 맵을 get_ytn_article_data 함수에 전달\n",
    "    article_data = get_ytn_article_data(url, headers, ytn_category_map)\n",
    "    extracted_data_list.append(article_data)\n",
    "    print(\"-\" * 30) # 구분선 출력\n",
    "\n",
    "print(\"\\n모든 URL 처리 완료.\")\n",
    "# --- 추출된 데이터를 Pandas DataFrame으로 변환 ---\n",
    "df_news = pd.DataFrame(extracted_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10e45711-157d-40c1-81ca-0e1f19ea6991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>제목</th>\n",
       "      <th>본문</th>\n",
       "      <th>카테고리</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ytn.co.kr/_ln/0102_202505111058245968</td>\n",
       "      <td>SK그룹, '정보보호혁신위원회' 구성 작업 착수</td>\n",
       "      <td>SK그룹 최태원 회장이 SK텔레콤 해킹 사고 이후 그룹 내 보안 강화 대책으로 발표...</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://www.ytn.co.kr/_ln/0102_202505111058245968   \n",
       "\n",
       "                           제목  \\\n",
       "0  SK그룹, '정보보호혁신위원회' 구성 작업 착수   \n",
       "\n",
       "                                                  본문 카테고리  \n",
       "0  SK그룹 최태원 회장이 SK텔레콤 해킹 사고 이후 그룹 내 보안 강화 대책으로 발표...   경제  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f3f5fa3-7c20-4c57-927c-d9126a60e0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    SK그룹 최태원 회장이 SK텔레콤 해킹 사고 이후 그룹 내 보안 강화 대책으로 발표...\n",
       "Name: 본문, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['본문']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "617263fe-2c86-435f-a209-027ac3e258a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/janghongseo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/Users/janghongseo/nltk_data'\n    - '/Users/janghongseo/Main/Develop/OSSassignment/.venv/nltk_data'\n    - '/Users/janghongseo/Main/Develop/OSSassignment/.venv/share/nltk_data'\n    - '/Users/janghongseo/Main/Develop/OSSassignment/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 예시 사용\u001b[39;00m\n\u001b[32m     39\u001b[39m text = df_news[\u001b[33m'\u001b[39m\u001b[33m본문\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m summary = \u001b[43msummarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m요약 결과:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m summary:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36msummarize\u001b[39m\u001b[34m(text, top_n)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msummarize\u001b[39m(text, top_n=\u001b[32m3\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     sentences = \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     embeddings = [get_sentence_embedding(sent) \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences]\n\u001b[32m     26\u001b[39m     embeddings = np.array(embeddings)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Main/Develop/OSSassignment/.venv/lib/python3.13/site-packages/nltk/tokenize/__init__.py:119\u001b[39m, in \u001b[36msent_tokenize\u001b[39m\u001b[34m(text, language)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msent_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    110\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \u001b[33;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     tokenizer = \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.tokenize(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Main/Develop/OSSassignment/.venv/lib/python3.13/site-packages/nltk/tokenize/__init__.py:105\u001b[39m, in \u001b[36m_get_punkt_tokenizer\u001b[39m\u001b[34m(language)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_punkt_tokenizer\u001b[39m(language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    a lru cache for performance.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m    :type language: str\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Main/Develop/OSSassignment/.venv/lib/python3.13/site-packages/nltk/tokenize/punkt.py:1744\u001b[39m, in \u001b[36mPunktTokenizer.__init__\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1743\u001b[39m     PunktSentenceTokenizer.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1744\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Main/Develop/OSSassignment/.venv/lib/python3.13/site-packages/nltk/tokenize/punkt.py:1749\u001b[39m, in \u001b[36mPunktTokenizer.load_lang\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1747\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m     lang_dir = \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;28mself\u001b[39m._params = load_punkt_params(lang_dir)\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28mself\u001b[39m._lang = lang\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Main/Develop/OSSassignment/.venv/lib/python3.13/site-packages/nltk/data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/Users/janghongseo/nltk_data'\n    - '/Users/janghongseo/Main/Develop/OSSassignment/.venv/nltk_data'\n    - '/Users/janghongseo/Main/Develop/OSSassignment/.venv/share/nltk_data'\n    - '/Users/janghongseo/Main/Develop/OSSassignment/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "\n",
    "# 문장 분리\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n",
    "model = BertModel.from_pretrained('monologg/kobert')\n",
    "model.eval()\n",
    "\n",
    "def get_sentence_embedding(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # [CLS] 토큰의 벡터 사용\n",
    "        return outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "\n",
    "import kss  # 한국어 문장 분리기\n",
    "\n",
    "def summarize(text, top_n=3):\n",
    "    sentences = kss.split_sentences(text)  # 여기만 변경\n",
    "    embeddings = [get_sentence_embedding(sent) for sent in sentences]\n",
    "    embeddings = np.array(embeddings)\n",
    "\n",
    "    sim_matrix = cosine_similarity(embeddings, embeddings)\n",
    "    scores = sim_matrix.sum(axis=1)\n",
    "\n",
    "    ranked_sentences = [sent for _, sent in sorted(zip(scores, sentences), reverse=True)]\n",
    "    return ranked_sentences[:top_n]\n",
    "\n",
    "\n",
    "# 예시 사용\n",
    "text = df_news['본문']\n",
    "summary = summarize(text)\n",
    "print(\"요약 결과:\")\n",
    "for sent in summary:\n",
    "    print(\"-\", sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf064c1a-4477-477f-b92d-4376d5e4478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kss\n",
      "  Downloading kss-6.0.4.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting emoji==1.2.0 (from kss)\n",
      "  Downloading emoji-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pecab (from kss)\n",
      "  Downloading pecab-1.0.8.tar.gz (26.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from kss) (3.4.2)\n",
      "Collecting jamo (from kss)\n",
      "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting hangul-jamo (from kss)\n",
      "  Downloading hangul_jamo-1.0.1-py3-none-any.whl.metadata (899 bytes)\n",
      "Collecting tossi (from kss)\n",
      "  Downloading tossi-0.3.1.tar.gz (11 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting distance (from kss)\n",
      "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyyaml==6.0 (from kss)\n",
      "  Downloading PyYAML-6.0.tar.gz (124 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[78 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/dist.py:761: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: MIT License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing lib/PyYAML.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to lib/PyYAML.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to lib/PyYAML.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/janghongseo/Main/Develop/OSSassignment/.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/janghongseo/Main/Develop/OSSassignment/.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m                              \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/janghongseo/Main/Develop/OSSassignment/.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m            \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m288\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/__init__.py\"\u001b[0m, line \u001b[35m117\u001b[0m, in \u001b[35msetup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return \u001b[31mdistutils.core.setup\u001b[0m\u001b[1;31m(**attrs)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m            \u001b[31m~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/_distutils/core.py\"\u001b[0m, line \u001b[35m186\u001b[0m, in \u001b[35msetup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/_distutils/core.py\"\u001b[0m, line \u001b[35m202\u001b[0m, in \u001b[35mrun_commands\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mdist.run_commands\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/_distutils/dist.py\"\u001b[0m, line \u001b[35m1002\u001b[0m, in \u001b[35mrun_commands\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_command\u001b[0m\u001b[1;31m(cmd)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/dist.py\"\u001b[0m, line \u001b[35m1106\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/_distutils/dist.py\"\u001b[0m, line \u001b[35m1021\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mcmd_obj.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/command/egg_info.py\"\u001b[0m, line \u001b[35m312\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.find_sources\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/command/egg_info.py\"\u001b[0m, line \u001b[35m320\u001b[0m, in \u001b[35mfind_sources\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mmm.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/command/egg_info.py\"\u001b[0m, line \u001b[35m543\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.add_defaults\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/command/egg_info.py\"\u001b[0m, line \u001b[35m581\u001b[0m, in \u001b[35madd_defaults\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msdist.add_defaults\u001b[0m\u001b[1;31m(self)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/command/sdist.py\"\u001b[0m, line \u001b[35m109\u001b[0m, in \u001b[35madd_defaults\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().add_defaults\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/_distutils/command/sdist.py\"\u001b[0m, line \u001b[35m245\u001b[0m, in \u001b[35madd_defaults\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself._add_defaults_ext\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/_distutils/command/sdist.py\"\u001b[0m, line \u001b[35m330\u001b[0m, in \u001b[35m_add_defaults_ext\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     self.filelist.extend(\u001b[31mbuild_ext.get_source_files\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "  \u001b[31m   \u001b[0m                          \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m204\u001b[0m, in \u001b[35mget_source_files\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/8v/lmh88sc94s904x9686hs_3n40000gn/T/pip-build-env-grajmsst/overlay/lib/python3.13/site-packages/setuptools/_distutils/cmd.py\"\u001b[0m, line \u001b[35m131\u001b[0m, in \u001b[35m__getattr__\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     raise AttributeError(attr)\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mAttributeError\u001b[0m: \u001b[35mcython_sources\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8564f13c-7c25-4bd3-bb56-f03179ffae5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
