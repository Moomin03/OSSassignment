{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f73d72-c71d-43a8-9f79-77b1b0e28fc0",
   "metadata": {},
   "source": [
    "## 🛜 필수 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8498d408-5079-43c0-a64c-ae0c6f3f178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1d3724-4f20-4921-a27f-3811bfba42c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- YTN 메인 메뉴 HTML 스니펫 (제공해주신 내용) ---\n",
    "# 이 HTML을 파싱하여 카테고리 맵을 생성합니다.\n",
    "ytn_menu_html_snippet = \"\"\"\n",
    "                <ul class=\"menu\">\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainpolitics menu_election2025\">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/issue/election2025\">대선2025</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainpolitics \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0101\">정치</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_maineconomy \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0102\">경제</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainsociety \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn\n",
    "                        .co.kr/news/list.php?mcd=0103\">사회</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainnationwide \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0115\">전국</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainglobal \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0104\">국제</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainscience \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0105\">과학</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainculture \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0106\">문화</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainsports \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/list.php?mcd=0107\">스포츠</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainphoto \">\n",
    "\t\t\t\t\t\t<a href=\"https://star.ytn.co.kr\">연예</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_maingame \">\n",
    "\t\t\t\t\t\t<!--<a href=\"https://game.ytn.co.kr/news/list.php?mcd=0135\">게임</a>-->\n",
    "\t\t\t\t\t\t<a href=\"https://game.ytn.co.kr\">게임</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainweather \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/weather/list_weather.php\">날씨</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainissue \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/main_issue.html\">이슈</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainyp \">\n",
    "\t\t\t\t\t\t<a href=\"https://www.ytn.co.kr/news/main_yp.html\">시리즈</a>\n",
    "\t\t\t\t\t</li>\n",
    "\t\t\t\t\t<li class=\"YTN_CSA_mainreplay \"><a href=\"https://www.ytn.co.kr/replay/main.html\">TV프로그램</a></li>\n",
    "\t\t\t\t</ul>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc7b105-506a-4f51-af90-568c7eb65877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 메뉴 HTML 파싱 및 카테고리 맵 생성 ---\n",
    "ytn_menu_soup = BeautifulSoup(ytn_menu_html_snippet, 'html.parser')\n",
    "ytn_category_map = {} # 카테고리 맵 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16948c74-8d77-4a4a-88fd-060154616d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 생성된 YTN 카테고리 맵 ---\n",
      "{'0101': '정치', '0102': '경제', '0103': '사회', '0115': '전국', '0104': '국제', '0105': '과학', '0106': '문화', '0107': '스포츠'}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 메뉴 HTML에서 a 태그들을 찾습니다.\n",
    "menu_links = ytn_menu_soup.select('ul.menu a')\n",
    "\n",
    "for link in menu_links:\n",
    "    href = link.get('href')\n",
    "    text = link.get_text(strip=True)\n",
    "    if href and text:\n",
    "        parsed_url = urlparse(href)\n",
    "        # URL 경로가 '/news/list.php'이고 쿼리 스트링에 'mcd' 파라미터가 있는 경우\n",
    "        if parsed_url.path == '/news/list.php' and parsed_url.query:\n",
    "            query_params = parse_qs(parsed_url.query)\n",
    "            if 'mcd' in query_params and query_params['mcd'][0]:\n",
    "                mcd_code = query_params['mcd'][0]\n",
    "                ytn_category_map[mcd_code] = text # mcd 코드를 키로, 카테고리 이름을 값으로 저장\n",
    "                # print(f\"맵핑 추가: {mcd_code} -> {text}\") # 디버깅용 출력\n",
    "\n",
    "# 생성된 카테고리 맵 확인 (선택 사항)\n",
    "print(\"--- 생성된 YTN 카테고리 맵 ---\")\n",
    "print(ytn_category_map)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91404df-8782-44ae-8efd-cb83aab8bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ytn_category_from_url(url, category_map):\n",
    "    \"\"\"\n",
    "    YTN 기사 URL 경로를 분석하여 카테고리 코드를 추출하고 맵핑된 카테고리 이름을 반환합니다.\n",
    "    생성된 category_map을 사용합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed_url = urlparse(url)\n",
    "        path = parsed_url.path # 예: '/_ln/0103_202505111017133914'\n",
    "        path_segments = path.split('/')\n",
    "        \n",
    "        if '_ln' in path_segments:\n",
    "            ln_index = path_segments.index('_ln')\n",
    "            if ln_index + 1 < len(path_segments):\n",
    "                # 예: '0103_202505111017133914'\n",
    "                code_segment = path_segments[ln_index + 1]\n",
    "                # 코드 세그먼트에서 첫 번째 '_' 이전 부분이 카테고리 코드입니다.\n",
    "                code = code_segment.split('_')[0] if '_' in code_segment else code_segment\n",
    "\n",
    "                # 생성된 category_map에서 코드를 찾아 카테고리 이름 반환\n",
    "                return category_map.get(code, f\"알 수 없는 카테고리 코드: {code}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"URL [{url}] 카테고리 분석 중 오류 발생: {e}\")\n",
    "\n",
    "    # 일치하는 패턴을 찾지 못하거나 오류 발생 시\n",
    "    return \"카테고리 분류 실패 (URL 패턴 불일치)\"\n",
    "\n",
    "def get_ytn_article_data(url, headers, category_map):\n",
    "    \"\"\"\n",
    "    단일 YTN 기사 URL에서 제목, 본문, 카테고리를 추출하는 함수\n",
    "    생성된 category_map을 인자로 받습니다.\n",
    "    \"\"\"\n",
    "    news_title = \"제목 추출 실패\"\n",
    "    news_body = \"본문 추출 실패\"\n",
    "    news_category = \"카테고리 추출 실패\" # 초기 카테고리 상태\n",
    "\n",
    "    print(f\"Processing URL: {url}\")\n",
    "\n",
    "    try:\n",
    "        # 1. 웹페이지 HTML 가져오기\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        html_content = response.text\n",
    "\n",
    "        # --- 디버깅: 가져온 HTML을 파일로 저장 ---\n",
    "        file_name_safe = re.sub(r'[^\\w.-]', '_', urlparse(url).path.strip('/')).strip('_')\n",
    "        if not file_name_safe: file_name_safe = urlparse(url).hostname or 'debug'\n",
    "        debug_file_path = f\"debug_ytn_html_{file_name_safe}.html\"\n",
    "        try:\n",
    "            with open(debug_file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(html_content)\n",
    "            print(f\"디버깅: 가져온 HTML 내용을 '{debug_file_path}' 파일로 저장했습니다.\")\n",
    "        except Exception as file_error:\n",
    "            print(f\"디버깅: HTML 파일 저장 중 오류 발생: {file_error}\")\n",
    "        # --- 디버깅 끝 ---\n",
    "\n",
    "        # 2. BeautifulSoup으로 파싱\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # --- 뉴스 제목 추출 (제공해주신 YTN 구조 반영) ---\n",
    "        # h2 태그에 class 'news_title'를 찾고, 그 안의 span 텍스트를 가져옵니다.\n",
    "        title_element_h2 = soup.find('h2', class_='news_title')\n",
    "\n",
    "        if title_element_h2:\n",
    "            title_element_span = title_element_h2.find('span')\n",
    "            if title_element_span:\n",
    "                news_title = title_element_span.get_text(strip=True)\n",
    "                print(f\"URL {url}: 제목 요소 (h2.news_title > span) 추출 성공.\")\n",
    "            else:\n",
    "                 news_title = title_element_h2.get_text(strip=True) if title_element_h2.get_text(strip=True) else news_title\n",
    "                 print(f\"URL {url}: <h2 class='news_title'> 태그를 찾았으나 <span>이 없어 <h2> 텍스트 추출 시도.\")\n",
    "        else:\n",
    "            print(f\"URL {url}: 제목 요소를 찾지 못했습니다. (예상 선택자: h2.news_title)\")\n",
    "\n",
    "\n",
    "        # --- 뉴스 본문 추출 (제공해주신 div#CmAdContent.paragraph 구조 반영) ---\n",
    "        # 본문 전체를 감싸는 div 요소를 찾습니다. id가 'CmAdContent'이고 class가 'paragraph'입니다.\n",
    "        body_container = soup.find('div', id='CmAdContent', class_='paragraph')\n",
    "        \n",
    "        news_body = \"본문 추출 실패\"\n",
    "\n",
    "        if body_container:\n",
    "            # 불필요한 요소 (예: iframe 광고, 이미지 등) 제거\n",
    "            for unnecessary_tag in body_container.find_all(['iframe', 'figure']):\n",
    "                unnecessary_tag.extract()\n",
    "\n",
    "            news_body_raw = body_container.get_text(separator='\\n', strip=True)\n",
    "\n",
    "            # 불필요한 내용 제거 및 정리 (YTN 기사 하단부 패턴 제거)\n",
    "            cleaned_body = news_body_raw\n",
    "            cleaned_body = re.sub(r'YTN\\s*[^(\\n)]+\\s*\\([^@]+\\@[^)]+\\)\\s*\\n*', '', cleaned_body, flags=re.MULTILINE)\n",
    "            cleaned_body = re.sub(r'※\\s*.*?\\[메일\\].*?\\n*', '', cleaned_body, flags=re.DOTALL)\n",
    "            cleaned_body = re.sub(r'\\[저작권자\\(c\\).+?\\]\\n*', '', cleaned_body)\n",
    "\n",
    "            news_body = re.sub(r'\\n\\s*\\n', '\\n\\n', cleaned_body).strip()\n",
    "\n",
    "            if news_body:\n",
    "                print(f\"URL {url}: 본문 요소 (div#CmAdContent.paragraph) 추출 성공.\")\n",
    "            else:\n",
    "                print(f\"URL {url}: 본문 컨테이너는 찾았으나, 유효한 텍스트 내용이 없습니다 (정리 후 빈 내용).\")\n",
    "                news_body = \"본문 내용 없음\"\n",
    "\n",
    "        else:\n",
    "            print(f\"URL {url}: 본문 전체 컨테이너 요소를 찾지 못했습니다. (예상 선택자: div#CmAdContent.paragraph)\")\n",
    "\n",
    "        # --- 뉴스 카테고리 추출 (URL 경로 분석 - 생성된 맵 사용) ---\n",
    "        # 생성된 ytn_category_map을 classify_ytn_category_from_url 함수에 전달\n",
    "        news_category = classify_ytn_category_from_url(url, category_map)\n",
    "        if news_category == \"카테고리 분류 실패 (URL 패턴 불일치)\" or news_category.startswith(\"알 수 없는 카테고리 코드\"):\n",
    "             print(f\"URL {url}: URL 구조 분석으로 카테고리 추출/분류 실패: {news_category}\")\n",
    "        else:\n",
    "             print(f\"URL {url}: URL 구조 분석으로 카테고리 '{news_category}' 추출 성공.\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"URL {url}: 웹페이지를 가져오는 중 오류 발생: {e}\")\n",
    "        # 요청 실패 시 제목, 본문, 카테고리는 초기 실패 값 유지\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"URL {url}: 데이터 처리 중 예외 발생: {e}\")\n",
    "        # 데이터 처리 중 오류 발생 시 해당 값들은 초기 실패 값 유지\n",
    "        if news_category == \"카테고리 추출 실패\": # 오류 발생했더라도 카테고리라도 추출 시도\n",
    "             news_category = classify_ytn_category_from_url(url, category_map) # 맵을 전달\n",
    "\n",
    "    # 최종 추출 결과 반환\n",
    "    return {\n",
    "        'URL': url,\n",
    "        '제목': news_title,\n",
    "        '본문': news_body,\n",
    "        '카테고리': news_category\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd7dd282-30f3-4d44-9f29-cb02a5266063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 크롤링할 YTN 뉴스 기사 URL 목록을 작성해주세요. ---\n",
    "news_urls_to_crawl = [\n",
    "    'http://ytn.co.kr/_ln/0103_202505111155162765'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6419b43-6150-47c2-94b8-1161c3525827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-Agent 설정\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4910f8ab-dc6f-43c2-a171-cb3fdae886ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL: http://ytn.co.kr/_ln/0103_202505111155162765\n",
      "디버깅: 가져온 HTML 내용을 'debug_ytn_html_ln_0103_202505111155162765.html' 파일로 저장했습니다.\n",
      "URL http://ytn.co.kr/_ln/0103_202505111155162765: 제목 요소 (h2.news_title > span) 추출 성공.\n",
      "URL http://ytn.co.kr/_ln/0103_202505111155162765: 본문 요소 (div#CmAdContent.paragraph) 추출 성공.\n",
      "URL http://ytn.co.kr/_ln/0103_202505111155162765: URL 구조 분석으로 카테고리 '사회' 추출 성공.\n",
      "------------------------------\n",
      "\n",
      "모든 URL 처리 완료.\n"
     ]
    }
   ],
   "source": [
    "# 추출된 데이터를 저장할 리스트\n",
    "extracted_data_list = []\n",
    "\n",
    "# 각 URL에 대해 크롤링 및 데이터 추출 반복\n",
    "for url in news_urls_to_crawl:\n",
    "    # 카테고리 맵을 get_ytn_article_data 함수에 전달\n",
    "    article_data = get_ytn_article_data(url, headers, ytn_category_map)\n",
    "    extracted_data_list.append(article_data)\n",
    "    print(\"-\" * 30) # 구분선 출력\n",
    "\n",
    "print(\"\\n모든 URL 처리 완료.\")\n",
    "# --- 추출된 데이터를 Pandas DataFrame으로 변환 ---\n",
    "df_news = pd.DataFrame(extracted_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10e45711-157d-40c1-81ca-0e1f19ea6991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>제목</th>\n",
       "      <th>본문</th>\n",
       "      <th>카테고리</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://ytn.co.kr/_ln/0103_202505111155162765</td>\n",
       "      <td>검찰, '공천 개입 의혹' 김건희 정식 소환 통보</td>\n",
       "      <td>[앵커]\\n정치 브로커 명태균 씨의 공천 개입 의혹을 수사하는 검찰이 김건희 여사에...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            URL                           제목  \\\n",
       "0  http://ytn.co.kr/_ln/0103_202505111155162765  검찰, '공천 개입 의혹' 김건희 정식 소환 통보   \n",
       "\n",
       "                                                  본문 카테고리  \n",
       "0  [앵커]\\n정치 브로커 명태균 씨의 공천 개입 의혹을 수사하는 검찰이 김건희 여사에...   사회  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f3f5fa3-7c20-4c57-927c-d9126a60e0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[앵커]\\n정치 브로커 명태균 씨의 공천 개입 의혹을 수사하는 검찰이 김건희 여사에게 이번 주 소환 조사를 받으라고 정식 통보한 것으로 전해졌습니다.\\n여러 차례 구두요청에 김 여사 측이 응하지 않자, 공식적으로 출석을 요구하고 나선 건데요.\\n취재기자 연결합니다. 부장원 기자!\\n자세한 소식 전해주시죠.\\n[기자]\\n명태균 씨를 고리로 한 공천개입 의혹을 수사하는 서울중앙지검 전담수사팀이 최근 김건희 여사 측에 출석 요구서를 보낸 것으로 파악됐습니다.\\n공직선거법과 정치자금법 위반 혐의를 받는 피의자 신분으로, 검찰청사로 출석해 조사받으라고 소환을 공식 통보한 겁니다.\\n검찰은 김 여사 측에 이번 주 중 하루 검찰청사에 출석할 것을 요구한 것으로 알려졌습니다.\\n앞서 수사팀은 지난 2월, 창원지검으로부터 명 씨 사건을 넘겨받은 직후 김 여사 측에 여러 차례 대면 조사가 필요하다고 요청해왔습니다.\\n하지만 김 여사 측이 별다른 응답을 내놓지 않으면서 일정 조율은 이뤄지지 못했습니다.\\n여기다 최근 조기 대선 국면이 본격화하면서 선거 전 소환이 어려워진 것 아니냐는 관측도 나왔는데요,\\n검찰은 이미 명 씨를 비롯한 의혹의 핵심 인물들로부터 충분한 진술과 물적 증거를 수집한 만큼,\\n의혹의 정점인 김 여사에 대한 조사를 더는 미룰 수 없다고 판단하고 이번에 공식적인 출석 요구 절차에 나선 거로 보입니다.\\n김 여사는 윤석열 전 대통령과 함께 지난 2022년 20대 대통령 선거 과정에서 명씨로부터 여론조사를 무상으로 제공 받고,\\n그 대가로 그해 6월 국회의원 보궐선거에서 김영선 전 국민의힘 의원이 경남 창원 의창 선거구에 공천받도록 했다는 혐의를 받습니다.\\n또, 같은 해 지방선거에서 국민의힘 포항시장 후보 공천에 개입하고, 지난해 총선을 앞두고 김상민 전 검사를 김 전 의원 선거구에 출마시키기 위해 영향력을 행사했다는 의혹도 있습니다.\\n[앵커]\\n조사가 초읽기에 들어간 모습인데요.\\n만약 김 여사가 소환에 응한다면 처음으로 검찰청사에 나와 조사를 받게 되는 거죠?\\n[기자]\\n김 여사, 그동안 여러 의혹에 연루돼 수사 선상에 올랐고,\\n검찰 조사도 이뤄진 적이 있지만 검찰청사로 직접 출석해 조사를 받는 건 이번이 처음입니다.\\n검찰은 지난해 7월 디올백 수수 의혹과 도이치모터스 주가조작 의혹과 관련해 김 여사를 대면 조사했는데요.\\n하지만 검찰청사가 아닌 대통령경호처가 관리하는 제3의 장소로 비공개 출장 조사를 벌여 '특혜 조사', '황제 조사' 논란이 불거졌습니다.\\n심지어 당시 이원석 검찰총장에게까지 사전에 조사 계획을 보고하지 않아 사상 초유의 '검찰총장 패싱 논란'도 불거졌습니다.\\n당시에는 김 여사가 영부인 신분이었던 만큼 경호상의 문제 등이 이유로 제시됐는데, 윤석열 전 대통령 파면으로 김 여사 역시 공적인 지위를 잃은 만큼 이제는 검찰청 출석을 피할 명분은 사라진 상황입니다.\\n출석 조사가 이뤄진다면 김 여사에 대해 제기된 의혹이 상당한 만큼 조사가 하루 안에 끝나지 않을 가능성도 점쳐집니다.\\n다만 김 여사가 출석 요구에 불응할 가능성도 남아 있습니다.\\n이 경우 검찰은 다시 소환을 통보하고, 정당한 사유 없이 계속해서 불응할 경우 체포영장을 발부받는 방안도 내부적으로 검토하는 것으로 알려졌는데요.\\n검찰은 김 여사를 먼저 조사한 뒤 윤 전 대통령도 조사할 것으로 보입니다.\\n지금까지 사회부에서 YTN 부장원입니다.\\n social@ytn.co.kr\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['본문'].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "617263fe-2c86-435f-a209-027ac3e258a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/janghongseo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "/Users/janghongseo/Main/Develop/hi/.venv/lib/python3.11/site-packages/pecab/_tokenizer.py:274: RuntimeWarning: overflow encountered in scalar add\n",
      "  least_cost += word_cost\n",
      "/Users/janghongseo/Main/Develop/hi/.venv/lib/python3.11/site-packages/pecab/_tokenizer.py:265: RuntimeWarning: overflow encountered in scalar add\n",
      "  from_pos_data.costs[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출석 조사가 이뤄진다면 김 여사에 대해 제기된 의혹이 상당한 만큼 조사가 하루 안에 끝나지 않을 가능성도 점쳐집니다. 검찰은 지난해 7월 디올백 수수 의혹과 도이치모터스 주가조작 의혹과 관련해 김 여사를 대면 조사했는데요. 이 경우 검찰은 다시 소환을 통보하고, 정당한 사유 없이 계속해서 불응할 경우 체포영장을 발부받는 방안도 내부적으로 검토하는 것으로 알려졌는데요. "
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "\n",
    "# 문장 분리\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n",
    "model = BertModel.from_pretrained('monologg/kobert')\n",
    "model.eval()\n",
    "\n",
    "def get_sentence_embedding(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # [CLS] 토큰의 벡터 사용\n",
    "        return outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "\n",
    "import kss  # 한국어 문장 분리기\n",
    "\n",
    "def summarize(text, top_n=3):\n",
    "    sentences = kss.split_sentences(text)\n",
    "    embeddings = [get_sentence_embedding(sent) for sent in sentences]\n",
    "    embeddings = np.array(embeddings)\n",
    "\n",
    "    sim_matrix = cosine_similarity(embeddings, embeddings)\n",
    "    scores = sim_matrix.sum(axis=1)\n",
    "\n",
    "    ranked_sentences = [sent for _, sent in sorted(zip(scores, sentences), reverse=True)]\n",
    "    return ranked_sentences[:top_n]\n",
    "\n",
    "\n",
    "# 예시 사용\n",
    "text = df_news['본문'].to_list()[0]\n",
    "summary = summarize(text)\n",
    "for i in summary:\n",
    "    print(i, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fcafe3-8be6-4a45-894a-cee46af26773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
